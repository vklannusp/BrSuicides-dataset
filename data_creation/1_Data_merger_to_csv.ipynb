{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASUS Data to Dataframe merger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merges all csv of all years into one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Prevent infinite warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OS and File imports\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files Location Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder structure:\n",
    "```\n",
    "root_folder/\n",
    "    data_storage/\n",
    "        attrs-utils/\"relevant_attributes_infos\"\n",
    "        datasus/\"all years csvs\"\n",
    "        utils/\"utility functions and data\"\n",
    "    data_creation/\n",
    "        0_Datasus_data_reader_v2.ipynb\n",
    "        1_Datasus_merger_to_csv.ipynb\n",
    "        2_Data_modeling.ipynb\n",
    "        3_Data_preprocessing.ipynb\n",
    "    plots/all_generated_plots...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User set folder path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Should change only the initial \"user_dir_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_storage/\n",
      "../data_storage/0_datasus_csvs/\n",
      "../data_storage/1_dirty/\n"
     ]
    }
   ],
   "source": [
    "# ---------------- USER SET FOLDER PATH ----------------\n",
    "user_dir_path = ''\n",
    "\n",
    "root_dir = '..'\n",
    "\n",
    "csv_dir = '/data_storage/'\n",
    "csv_dir_datasus = csv_dir + '0_datasus_csvs/'\n",
    "csv_dir_dirty = csv_dir + '1_dirty/'\n",
    "# csv_dir_clean = csv_dir + '2_clean/'\n",
    "# csv_dir_preprocessed = csv_dir + '3_preprocessed/'\n",
    "\n",
    "csv_data_dir = os.path.dirname(root_dir + csv_dir) + '/'\n",
    "print(csv_data_dir)\n",
    "\n",
    "datasus_data_dir = os.path.dirname(root_dir + csv_dir_datasus) + '/'\n",
    "print(datasus_data_dir)\n",
    "csv_data_dir_dirty = os.path.dirname(root_dir + csv_dir_dirty) + '/'\n",
    "print(csv_data_dir_dirty)\n",
    "# csv_data_dir_clean = os.path.dirname(root_dir + csv_dir_clean) + '/'\n",
    "# print(csv_data_dir_clean)\n",
    "# csv_data_dir_preprocessed = os.path.dirname(root_dir + csv_dir_preprocessed) + '/'\n",
    "# print(csv_data_dir_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is specific for Data_merger_to_csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zips:  \n",
      " ['suicidios-brazil-1996_2022.zip']\n",
      "Zip file name:  \n",
      " suicidios-brazil-1996_2022.zip\n",
      "Region name:  \n",
      " brazil\n",
      "Years interval:  \n",
      " ['1996', '2022']\n",
      "Years: \n",
      " [1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n"
     ]
    }
   ],
   "source": [
    "# List all files in the csvs directory\n",
    "all_files = os.listdir(datasus_data_dir)\n",
    "\n",
    "# Filter for files that end with .zip extension\n",
    "zip_files = [file for file in all_files if file.endswith('.zip')]\n",
    "print('Zips: ', '\\n', zip_files)\n",
    "\n",
    "# Filter for files that end with .zip extension\n",
    "zip_file_name = zip_files[0]\n",
    "print('Zip file name: ', '\\n', zip_file_name)\n",
    "\n",
    "# Get region name\n",
    "region_name = zip_files[0].split('-')[1]\n",
    "print('Region name: ', '\\n', region_name)\n",
    "\n",
    "years_interval = zip_files[0].split('-')[2].split('_')\n",
    "years_interval[1] = years_interval[1][0:4]\n",
    "print('Years interval: ', '\\n' , years_interval)\n",
    "\n",
    "# Years that will be downloaded, [1996,2023) interval\n",
    "years = [x for x in range(int(years_interval[0]), (int(years_interval[-1]) + 1))]\n",
    "# years = [1996, 1997, 1998, 1999, 2000, 2001, 2002, \n",
    "#          2003, 2004, 2005, 2006, 2007, 2008, 2009, \n",
    "#          2010, 2011, 2012, 2013, 2014, 2015, 2016, \n",
    "#          2017, 2018, 2019, 2020, 2021, 2022, \n",
    "#        # 2023\n",
    "#          ]\n",
    "\n",
    "print('Years:', '\\n' , years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_storage/0_datasus_csvs/\n",
      "../data_storage/0_datasus_csvs/suicidios-brazil-1996_2022.zip\n",
      "\n",
      "CSV Filename:  \n",
      " suicidios-brazil-1996_2022.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to zip file\n",
    "zip_path = user_dir_path + datasus_data_dir\n",
    "print(zip_path)\n",
    "# Path with parquet file .zip\n",
    "zip_path_files = user_dir_path + datasus_data_dir + zip_file_name\n",
    "print(zip_path_files)\n",
    "\n",
    "# Path to zip file on colab\n",
    "# zip_file_path_colab = google_colab_dir + user_colab_folder_path + datasus_data_dir\n",
    "# print(zip_file_path_colab)\n",
    "# Path with parquet file .zip on colab\n",
    "# zip_path_files_colab = google_colab_dir + user_colab_folder_path + datasus_data_dir + zip_file_name\n",
    "# print(zip_path_files_colab)\n",
    "\n",
    "# Setting csv file name\n",
    "df_csv_filename = 'suicidios-' + region_name + '-' + years_interval[0] + '_' + years_interval[-1] + '.csv'\n",
    "print('\\nCSV Filename: ', '\\n', df_csv_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV / Parquet to Dataframe conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files: ['1996.csv', '1997.csv', '1998.csv', '1999.csv', '2000.csv', '2001.csv', '2002.csv', '2003.csv', '2004.csv', '2005.csv', '2006.csv', '2007.csv', '2008.csv', '2009.csv', '2010.csv', '2011.csv', '2012.csv', '2013.csv', '2014.csv', '2015.csv', '2016.csv', '2017.csv', '2018.csv', '2019.csv', '2020.csv', '2021.csv', '2022.csv']\n"
     ]
    }
   ],
   "source": [
    "# CSV CONVERSION\n",
    "\n",
    "# Initialize csv_to_df\n",
    "csv_to_df = pd.DataFrame()\n",
    "\n",
    "# with ZipFile(zip_path_files_colab, 'r') as z:\n",
    "with ZipFile(zip_path_files, 'r') as z:\n",
    "    # List comprehension to find all CSV files within the zip\n",
    "    csv_files = sorted([f for f in z.namelist() if f.endswith('.csv')])\n",
    "    print('CSV files:', csv_files)\n",
    "    \n",
    "    # Iterate through the list of CSV files\n",
    "    for csvf in csv_files:\n",
    "        # BytesIO to read file into memory, then read with Pandas\n",
    "        with z.open(csvf) as f:\n",
    "            temp_df = pd.read_csv(BytesIO(f.read()))\n",
    "        \n",
    "        # Concatenate current DataFrame with the Resulting DataFrame\n",
    "        csv_to_df = pd.concat([csv_to_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Local PC\n",
    "csv_to_df.to_csv(csv_data_dir_dirty + df_csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARQUET CONVERSION\n",
    "\n",
    "# # Initialize parquet_to_df\n",
    "# parquet_to_df = pd.DataFrame()\n",
    "\n",
    "# # with ZipFile(zip_path_files_colab, 'r') as z:\n",
    "# with ZipFile(zip_path_files, 'r') as z:\n",
    "#     # List comprehension to find all Parquet files within the zip\n",
    "#     parquet_files = [f for f in z.namelist() if f.endswith('.parquet')]\n",
    "    \n",
    "#     for pf in parquet_files:\n",
    "#         # BytesIO to read file into memory, then read with Pandas\n",
    "#         with z.open(pf) as f:\n",
    "#             temp_df = pd.read_parquet(BytesIO(f.read()))\n",
    "        \n",
    "#         # Concatenate current DataFrame with the Resulting DataFrame\n",
    "#         parquet_to_df = pd.concat([parquet_to_df, temp_df], ignore_index=True)\n",
    "\n",
    "# # Local PC\n",
    "# parquet_to_df.to_csv(df_csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(csv_data_dir_dirty + df_csv_filename, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268028 entries, 0 to 268027\n",
      "Columns: 103 entries, ESTADO to ALTCAUSA\n",
      "dtypes: float64(3), int64(6), object(94)\n",
      "memory usage: 210.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = dataframe.dropna(axis=\"columns\", how=\"all\")\n",
    "# dataframe.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb4aedbb3e48fcade389134a65d3ea28af6182719d78c5808dc7229455b745bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
